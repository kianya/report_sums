{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models import FairseqEncoderDecoderModel, register_model\n",
    "\n",
    "# Note: the register_model \"decorator\" should immediately precede the\n",
    "# definition of the Model class.\n",
    "\n",
    "@register_model('simple_lstm')\n",
    "class SimpleLSTMModel(FairseqEncoderDecoderModel):\n",
    "\n",
    "    @staticmethod\n",
    "    def add_args(parser):\n",
    "        # Models can override this method to add new command-line arguments.\n",
    "        # Here we'll add some new command-line arguments to configure dropout\n",
    "        # and the dimensionality of the embeddings and hidden states.\n",
    "        parser.add_argument(\n",
    "            '--encoder-embed-dim', type=int, metavar='N',\n",
    "            help='dimensionality of the encoder embeddings',\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--encoder-hidden-dim', type=int, metavar='N',\n",
    "            help='dimensionality of the encoder hidden state',\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--encoder-dropout', type=float, default=0.1,\n",
    "            help='encoder dropout probability',\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--decoder-embed-dim', type=int, metavar='N',\n",
    "            help='dimensionality of the decoder embeddings',\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--decoder-hidden-dim', type=int, metavar='N',\n",
    "            help='dimensionality of the decoder hidden state',\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            '--decoder-dropout', type=float, default=0.1,\n",
    "            help='decoder dropout probability',\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def build_model(cls, args, task):\n",
    "        # Fairseq initializes models by calling the ``build_model()``\n",
    "        # function. This provides more flexibility, since the returned model\n",
    "        # instance can be of a different type than the one that was called.\n",
    "        # In this case we'll just return a SimpleLSTMModel instance.\n",
    "\n",
    "        # Initialize our Encoder and Decoder.\n",
    "        encoder = SimpleLSTMEncoder(\n",
    "            args=args,\n",
    "            dictionary=task.source_dictionary,\n",
    "            embed_dim=args.encoder_embed_dim,\n",
    "            hidden_dim=args.encoder_hidden_dim,\n",
    "            dropout=args.encoder_dropout,\n",
    "        )\n",
    "        decoder = SimpleLSTMDecoder(\n",
    "            dictionary=task.target_dictionary,\n",
    "            encoder_hidden_dim=args.encoder_hidden_dim,\n",
    "            embed_dim=args.decoder_embed_dim,\n",
    "            hidden_dim=args.decoder_hidden_dim,\n",
    "            dropout=args.decoder_dropout,\n",
    "        )\n",
    "        model = SimpleLSTMModel(encoder, decoder)\n",
    "\n",
    "        # Print the model architecture.\n",
    "        print(model)\n",
    "\n",
    "        return model\n",
    "\n",
    "    # We could override the ``forward()`` if we wanted more control over how\n",
    "    # the encoder and decoder interact, but it's not necessary for this\n",
    "    # tutorial since we can inherit the default implementation provided by\n",
    "    # the FairseqEncoderDecoderModel base class, which looks like:\n",
    "    #\n",
    "    # def forward(self, src_tokens, src_lengths, prev_output_tokens):\n",
    "    #     encoder_out = self.encoder(src_tokens, src_lengths)\n",
    "    #     decoder_out = self.decoder(prev_output_tokens, encoder_out)\n",
    "    #     return decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models import register_model_architecture\n",
    "\n",
    "# The first argument to ``register_model_architecture()`` should be the name\n",
    "# of the model we registered above (i.e., 'simple_lstm'). The function we\n",
    "# register here should take a single argument *args* and modify it in-place\n",
    "# to match the desired architecture.\n",
    "\n",
    "@register_model_architecture('simple_lstm', 'tutorial_simple_lstm')\n",
    "def tutorial_simple_lstm(args):\n",
    "    # We use ``getattr()`` to prioritize arguments that are explicitly given\n",
    "    # on the command-line, so that the defaults defined below are only used\n",
    "    # when no other value has been specified.\n",
    "    args.encoder_embed_dim = getattr(args, 'encoder_embed_dim', 256)\n",
    "    args.encoder_hidden_dim = getattr(args, 'encoder_hidden_dim', 256)\n",
    "    args.decoder_embed_dim = getattr(args, 'decoder_embed_dim', 256)\n",
    "    args.decoder_hidden_dim = getattr(args, 'decoder_hidden_dim', 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fairseq in /home/kianya/.local/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex in /home/kianya/.local/lib/python3.6/site-packages (from fairseq) (2020.4.4)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.14)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.42.0)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0.dev20200128)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.1)\n",
      "Requirement already satisfied: sacrebleu in /home/kianya/.local/lib/python3.6/site-packages (from fairseq) (1.4.9)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.19)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.7.4.1)\n",
      "Requirement already satisfied: portalocker in /home/kianya/.local/lib/python3.6/site-packages (from sacrebleu->fairseq) (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install fairseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: fairseq-train: not found\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train data-bin/iwslt14.tokenized.de-en \\\n",
    "  --arch tutorial_simple_lstm \\\n",
    "  --encoder-dropout 0.2 --decoder-dropout 0.2 \\\n",
    "  --optimizer adam --lr 0.005 --lr-shrink 0.5 \\\n",
    "  --max-tokens 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\n"
     ]
    }
   ],
   "source": [
    "! python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
